{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNAgsEX5q/By9KaK9jxKlob"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e7d5b1bfc571413b97b1c0860c565728":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2cb1c817f2e145a39076a5c806d0d4de","IPY_MODEL_877f4d6ba5804a6b95acc46b9bf8fb18","IPY_MODEL_8ad0fe30e74246dea2ffd371907b221a"],"layout":"IPY_MODEL_c6520896a3164c6f8d6dca7a4d3d3c47"}},"2cb1c817f2e145a39076a5c806d0d4de":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07540f24fc124c7b88def70e31c9e2bd","placeholder":"​","style":"IPY_MODEL_0fb22e7fa0b44c42b3ac1f609f77b856","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"877f4d6ba5804a6b95acc46b9bf8fb18":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_10a96908327c4bc997d51732000d890b","max":213450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_51ec5d20cf744659bdf34ae6dccc2d54","value":213450}},"8ad0fe30e74246dea2ffd371907b221a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_976b48ad726f4ee199c859556cf111fa","placeholder":"​","style":"IPY_MODEL_b3041dfbb53a45ab8dab366a6f621940","value":" 213k/213k [00:00&lt;00:00, 1.64MB/s]"}},"c6520896a3164c6f8d6dca7a4d3d3c47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07540f24fc124c7b88def70e31c9e2bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0fb22e7fa0b44c42b3ac1f609f77b856":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"10a96908327c4bc997d51732000d890b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51ec5d20cf744659bdf34ae6dccc2d54":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"976b48ad726f4ee199c859556cf111fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3041dfbb53a45ab8dab366a6f621940":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d50e350a4a78496286949de341a2be30":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e5927d4d5cc3447d94eba923d84e33a5","IPY_MODEL_54591de309ad41559b7ffe8ca0e842cb","IPY_MODEL_80afa089a0fc4249bfff0bee1c7c1aac"],"layout":"IPY_MODEL_5ccbb898410b4e0c8ab27c98edc366ca"}},"e5927d4d5cc3447d94eba923d84e33a5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0879c80e5ec3435f875ab080f0411af1","placeholder":"​","style":"IPY_MODEL_25e50f7dc2bb48bf880ffab0efd4f31d","value":"Downloading (…)okenizer_config.json: 100%"}},"54591de309ad41559b7ffe8ca0e842cb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_76510d4dc8994b38a899f9479823947e","max":29,"min":0,"orientation":"horizontal","style":"IPY_MODEL_29057bc9adbd4f5d9486eda124b26dc8","value":29}},"80afa089a0fc4249bfff0bee1c7c1aac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ab7b97405a8457491a1649f00ed60f5","placeholder":"​","style":"IPY_MODEL_9f37128cd1164d879cddfdddd5f39ad9","value":" 29.0/29.0 [00:00&lt;00:00, 519B/s]"}},"5ccbb898410b4e0c8ab27c98edc366ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0879c80e5ec3435f875ab080f0411af1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25e50f7dc2bb48bf880ffab0efd4f31d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"76510d4dc8994b38a899f9479823947e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29057bc9adbd4f5d9486eda124b26dc8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7ab7b97405a8457491a1649f00ed60f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f37128cd1164d879cddfdddd5f39ad9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c832a6a5d5fd4240a67d9f0fe5785ba7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9855511efc5c4ef3a553b53761aa6345","IPY_MODEL_ebffa64880714b908ae664ce2073ab85","IPY_MODEL_89d4ceb7bd944a18a314d3923ab330be"],"layout":"IPY_MODEL_b483b08c4b934fa99d9c036cafc8a941"}},"9855511efc5c4ef3a553b53761aa6345":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_998355d0ccf64d8eb192b1f9ef54f451","placeholder":"​","style":"IPY_MODEL_acf8ed662e0947b9af61e95c3a4b086e","value":"Downloading (…)lve/main/config.json: 100%"}},"ebffa64880714b908ae664ce2073ab85":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef1a1585d64948949f5057cc195944b7","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c19c22cac12a4874ae538d98700b0ca7","value":570}},"89d4ceb7bd944a18a314d3923ab330be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c249bd0fee9a4a08ad9e624b41b884d7","placeholder":"​","style":"IPY_MODEL_2c34bda8c28e468f9f9fddc40aad22e3","value":" 570/570 [00:00&lt;00:00, 12.9kB/s]"}},"b483b08c4b934fa99d9c036cafc8a941":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"998355d0ccf64d8eb192b1f9ef54f451":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"acf8ed662e0947b9af61e95c3a4b086e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef1a1585d64948949f5057cc195944b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c19c22cac12a4874ae538d98700b0ca7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c249bd0fee9a4a08ad9e624b41b884d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c34bda8c28e468f9f9fddc40aad22e3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Tokenizers"],"metadata":{"id":"FB7cezcjL54K"}},{"cell_type":"markdown","source":["Doc: https://huggingface.co/docs/transformers/main_classes/tokenizer"],"metadata":{"id":"xsQEuPtXiLvB"}},{"cell_type":"markdown","source":["Common functions;\n","\n","- **tokenizer.tokenize(text)**: This function tokenizes a single input text into a list of tokens. It splits the text into subword units or word pieces, depending on the tokenizer's underlying tokenization algorithm.\n","\n","- **tokenizer.encode(text)**: This function encodes a single input text into a sequence of token IDs. It tokenizes the text and maps each token to its corresponding token ID in the vocabulary.\n","\n","- **tokenizer.decode(tokens)**: This function decodes a list of token IDs back into a single text string. It converts the token IDs into their corresponding tokens and concatenates them into a text string.\n","\n","- **tokenizer.batch_encode_plus(texts)**: This function encodes a list of input texts into tokenized sequences with additional information. It returns a dictionary containing the encoded sequences, attention masks, and other relevant information.\n","\n","- **tokenizer.batch_decode(tokens)**: This function decodes a list of tokenized sequences (lists of token IDs) back into a list of text strings. It performs the decoding operation on multiple sequences at once.\n","\n","- **tokenizer.pad**: This attribute provides options for padding input sequences to a fixed length. It allows you to add padding tokens to make all sequences of the same length for batch processing.\n","\n","- **tokenizer.special_tokens_map**: This attribute provides a mapping of special tokens used by the tokenizer. It includes tokens like [CLS], [SEP], [UNK], and [PAD], which are commonly used in transformer-based models."],"metadata":{"id":"bqlluVY-iE6E"}},{"cell_type":"code","source":["!apt-get install tree"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fJDs-YEOdJQY","executionInfo":{"status":"ok","timestamp":1688131124784,"user_tz":-540,"elapsed":8599,"user":{"displayName":"Jing Wora","userId":"14098338404840441752"}},"outputId":"10070ca8-aafa-4ca7-ea2f-6732a22ec648"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following NEW packages will be installed:\n","  tree\n","0 upgraded, 1 newly installed, 0 to remove and 14 not upgraded.\n","Need to get 43.0 kB of archives.\n","After this operation, 115 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 tree amd64 1.8.0-1 [43.0 kB]\n","Fetched 43.0 kB in 0s (636 kB/s)\n","Selecting previously unselected package tree.\n","(Reading database ... 123069 files and directories currently installed.)\n","Preparing to unpack .../tree_1.8.0-1_amd64.deb ...\n","Unpacking tree (1.8.0-1) ...\n","Setting up tree (1.8.0-1) ...\n","Processing triggers for man-db (2.9.1-1) ...\n"]}]},{"cell_type":"code","source":["!pip install -q datasets evaluate transformers[sentencepiece]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dh5T0f6TXI7s","executionInfo":{"status":"ok","timestamp":1688129565029,"user_tz":-540,"elapsed":18061,"user":{"displayName":"Jing Wora","userId":"14098338404840441752"}},"outputId":"202d445e-6cbe-4764-88cc-e2e274f506f4"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/486.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m481.3/486.2 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"markdown","source":["## Tokenization\n","\n","- Tokenization is the process split text into words (or parts of words, punctuation symbols, etc.), usually called tokens.\n","- Tokenizers convert text into input data for model.\n","- When you call your tokenizer directly on the sentence, you get back inputs that are ready to pass through your model"],"metadata":{"id":"JkYB_vjiNkgf"}},{"cell_type":"markdown","source":["unknown\n","- token that are not in our vocabulary.\n","- often represented as ”[UNK]”"],"metadata":{"id":"hlDbDgiyU9YV"}},{"cell_type":"markdown","source":["## Encoding\n","\n","- To convert text to numbers is known as encoding.\n","- Encoding is done in a two-step process: the tokenization, followed by the conversion to input IDs."],"metadata":{"id":"40bDB0nggyK1"}},{"cell_type":"markdown","source":["## Decoding\n","\n","- To convert index number to text."],"metadata":{"id":"RrdzQ1ODhbaw"}},{"cell_type":"markdown","source":["## 1. Word-based Tokenization\n","- Breaking down a piece of text into individual words, where each word represents a separate token.\n","\n","- Pros:\n","  - Simple and easy to implement\n","\n","- Cons:\n","  - Not suitable for all languages (do not use spaces to separate words)\n","  - May not handle all types of words correctly. (\"don't)\n","  - Huge amount of token (500,000 words in English)\n","\n","- Library: spaCy, Moses"],"metadata":{"id":"8BGZbISMQuvu"}},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LiaCz2iWLQQm","executionInfo":{"status":"ok","timestamp":1688129829284,"user_tz":-540,"elapsed":381,"user":{"displayName":"Jing Wora","userId":"14098338404840441752"}},"outputId":"d46adb4f-c851-493c-a5e1-c97a4ecca0ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["['I', 'am', 'a', 'programmer']\n"]}],"source":["text = \"I am a programmer\".split()\n","\n","print(text)"]},{"cell_type":"code","source":["tokenized_text = \"トムはプログラマーです。\".split()\n","\n","print(tokenized_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kBmsVPGTUAnW","executionInfo":{"status":"ok","timestamp":1688128793982,"user_tz":-540,"elapsed":5,"user":{"displayName":"Jing Wora","userId":"14098338404840441752"}},"outputId":"b62c9a6d-d9c5-4512-f9db-dddb70798125"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["['トムはプログラマーです。']\n"]}]},{"cell_type":"markdown","source":["## 2. Character-based tokenization\n","\n","- Breaking down a piece of text into individual characters, where each character represents a separate token.\n","\n","- Pros:\n","  - The vocabulary is much smaller.\n","  - There are much fewer out-of-vocabulary (unknown) tokens. (unusual or rare words)\n","\n","- Cons:\n","  - Can lose some contextual information"],"metadata":{"id":"8DS-pICCT6Kn"}},{"cell_type":"markdown","source":["## 3. Subword-based Tokenization\n","- Breaking down a piece of text into smaller units of meaning, known as subwords.\n","\n","- Pros:\n","  - Can handle complex morphology\n","  - Can improve performance\n","\n","- Cons:\n","  - May require additional preprocessing\n","\n","- Techniques:\n","  - Byte-level BPE (GPT-2)\n","  - WordPiece (BERT)\n","  - SentencePiece or Unigram, as used in several multilingual models"],"metadata":{"id":"T71cRR3fV9ww"}},{"cell_type":"code","source":["from transformers import BertTokenizer\n","\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n","\n","# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["e7d5b1bfc571413b97b1c0860c565728","2cb1c817f2e145a39076a5c806d0d4de","877f4d6ba5804a6b95acc46b9bf8fb18","8ad0fe30e74246dea2ffd371907b221a","c6520896a3164c6f8d6dca7a4d3d3c47","07540f24fc124c7b88def70e31c9e2bd","0fb22e7fa0b44c42b3ac1f609f77b856","10a96908327c4bc997d51732000d890b","51ec5d20cf744659bdf34ae6dccc2d54","976b48ad726f4ee199c859556cf111fa","b3041dfbb53a45ab8dab366a6f621940","d50e350a4a78496286949de341a2be30","e5927d4d5cc3447d94eba923d84e33a5","54591de309ad41559b7ffe8ca0e842cb","80afa089a0fc4249bfff0bee1c7c1aac","5ccbb898410b4e0c8ab27c98edc366ca","0879c80e5ec3435f875ab080f0411af1","25e50f7dc2bb48bf880ffab0efd4f31d","76510d4dc8994b38a899f9479823947e","29057bc9adbd4f5d9486eda124b26dc8","7ab7b97405a8457491a1649f00ed60f5","9f37128cd1164d879cddfdddd5f39ad9","c832a6a5d5fd4240a67d9f0fe5785ba7","9855511efc5c4ef3a553b53761aa6345","ebffa64880714b908ae664ce2073ab85","89d4ceb7bd944a18a314d3923ab330be","b483b08c4b934fa99d9c036cafc8a941","998355d0ccf64d8eb192b1f9ef54f451","acf8ed662e0947b9af61e95c3a4b086e","ef1a1585d64948949f5057cc195944b7","c19c22cac12a4874ae538d98700b0ca7","c249bd0fee9a4a08ad9e624b41b884d7","2c34bda8c28e468f9f9fddc40aad22e3"]},"id":"ef5etXPcWRSQ","executionInfo":{"status":"ok","timestamp":1688129622920,"user_tz":-540,"elapsed":5173,"user":{"displayName":"Jing Wora","userId":"14098338404840441752"}},"outputId":"e3a21c2b-5e07-4ffd-9cfb-fbf5e4e07779"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7d5b1bfc571413b97b1c0860c565728"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d50e350a4a78496286949de341a2be30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c832a6a5d5fd4240a67d9f0fe5785ba7"}},"metadata":{}}]},{"cell_type":"code","source":["text = \"I am a programmer\".split()\n","\n","tokenizer(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RaqqlhINT7XV","executionInfo":{"status":"ok","timestamp":1688129852338,"user_tz":-540,"elapsed":2,"user":{"displayName":"Jing Wora","userId":"14098338404840441752"}},"outputId":"8bee23ec-1f3a-4c4c-ea00-bab5d8854363"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [[101, 146, 102], [101, 1821, 102], [101, 170, 102], [101, 23981, 102]], 'token_type_ids': [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]], 'attention_mask': [[1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1]]}"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["### 3.1 BPE (Byte Pair Encoding)\n","\n","- initially developed as an algorithm to compress texts\n","\n","- Iteratively merging the most frequent pair of consecutive bytes or characters in a corpus until a predefined vocabulary size is reached.\n","- BPE relies on a pre-tokenizer that splits the training data into words.\n","\n","- GPT, GPT-2, Roberta, XLM, BART, DeBERTa, FlauBERT\n","\n","- GPT has a vocabulary size of 40,478 since they have 478 base characters and chose to stop training after 40,000 merges.\n","\n","\n","\n","- Papaer: https://arxiv.org/abs/1508.07909\n","\n","- Ref: https://huggingface.co/learn/nlp-course/chapter6/5?fw=pt"],"metadata":{"id":"uccfzZeraa-R"}},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","\n","text = \"I am a programmer.\"\n","\n","model_name = \"gpt2\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","tokens = tokenizer.tokenize(text)\n","ids = tokenizer.encode(text)\n","\n","# Print the tokens\n","print(len(tokens))\n","print(tokens)\n","print(ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"opNtcle3a8cu","executionInfo":{"status":"ok","timestamp":1688132320167,"user_tz":-540,"elapsed":1065,"user":{"displayName":"Jing Wora","userId":"14098338404840441752"}},"outputId":"7b961dcf-3835-4c1f-c533-65079519e872"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["5\n","['I', 'Ġam', 'Ġa', 'Ġprogrammer', '.']\n","[40, 716, 257, 24292, 13]\n"]}]},{"cell_type":"code","source":["# Decoding\n","\n","decoded_string = tokenizer.decode(ids)\n","\n","print(decoded_string)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F-XO68EjhnEV","executionInfo":{"status":"ok","timestamp":1688132329639,"user_tz":-540,"elapsed":9473,"user":{"displayName":"Jing Wora","userId":"14098338404840441752"}},"outputId":"268cff07-3953-4e91-96e7-3cca3f2986c2"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["I am a programmer.\n"]}]},{"cell_type":"markdown","source":["### 3.2 WordPiece\n","\n","- Google developed to pretrain BERT\n","- Iteratively merging the most frequent pair by score (dividing the frequency of the pair by the product of the frequencies of each of its parts)\n","- The algorithm prioritizes the merging of pairs where the individual parts are less frequent in the vocabulary.\n","- WordPiece only saves the final vocabulary, not the merge rules learned.\n","\n","- DistilBERT, MobileBERT\n"],"metadata":{"id":"jxnIXUfmasa1"}},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","\n","text = \"I am a programmer.\"\n","\n","model_name = \"distilbert-base-multilingual-cased\"  # distilbert-base-multilingual-cased\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","tokens = tokenizer.tokenize(text)\n","ids = tokenizer.encode(text)\n","\n","# Print the tokens\n","print(len(tokens))\n","print(tokens)\n","print(ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SfhAYCkWbRSd","executionInfo":{"status":"ok","timestamp":1688132193680,"user_tz":-540,"elapsed":556,"user":{"displayName":"Jing Wora","userId":"14098338404840441752"}},"outputId":"6469ab58-1c0f-4092-96d1-67d1ff8ea5e7"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["6\n","['I', 'am', 'a', 'programme', '##r', '.']\n","[101, 146, 10392, 169, 19611, 10129, 119, 102]\n"]}]},{"cell_type":"markdown","source":["### 3.3 Unigram\n","\n","- The Unigram algorithm is often used in SentencePiece\n","- SentencePiece uses a more efficient algorithm called Enhanced Suffix Array (ESA) to create the initial vocabulary.\n","- Starts from a big vocabulary and removes tokens from it until it reaches the desired vocabulary size.\n","- Iteratively remove the token that least impacts the loss\n","- Very costly operation\n","- AlBERT, mT5, mBART, Big Bird, and XLNet\n","- Ref: https://huggingface.co/learn/nlp-course/chapter6/7?fw=pt"],"metadata":{"id":"F0sSyoAXa0Tt"}},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","\n","text = \"I am a programmer.\"\n","\n","model_name = \"t5-small\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","tokens = tokenizer.tokenize(text)\n","ids = tokenizer.encode(text)\n","\n","# Print the tokens\n","print(len(tokens))\n","print(tokens)\n","print(ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rYRJcKHEbbE_","executionInfo":{"status":"ok","timestamp":1688132202634,"user_tz":-540,"elapsed":517,"user":{"displayName":"Jing Wora","userId":"14098338404840441752"}},"outputId":"90279858-1467-447b-8642-93209d23b8e2"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","['▁I', '▁am', '▁', 'a', '▁programme', 'r', '.']\n","[27, 183, 3, 9, 2486, 52, 5, 1]\n"]}]},{"cell_type":"markdown","source":["## Saving tokenizer"],"metadata":{"id":"MEKmt5d5WTex"}},{"cell_type":"code","source":["save_folder = \"/content/tokenizer\"\n","\n","tokenizer.save_pretrained(save_folder)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0WPF_9hdcfPv","executionInfo":{"status":"ok","timestamp":1688131090118,"user_tz":-540,"elapsed":340,"user":{"displayName":"Jing Wora","userId":"14098338404840441752"}},"outputId":"5e1a9577-e5fd-44a9-f211-88f9272aa393"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('/content/tokenizer/tokenizer_config.json',\n"," '/content/tokenizer/special_tokens_map.json',\n"," '/content/tokenizer/spiece.model',\n"," '/content/tokenizer/added_tokens.json',\n"," '/content/tokenizer/tokenizer.json')"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["!tree -h \"/content/tokenizer\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ltq3mArMdEy4","executionInfo":{"status":"ok","timestamp":1688131148230,"user_tz":-540,"elapsed":12,"user":{"displayName":"Jing Wora","userId":"14098338404840441752"}},"outputId":"6dc99810-da30-4612-9f7d-5719efa05960"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[01;34m/content/tokenizer\u001b[00m\n","├── [2.1K]  special_tokens_map.json\n","├── [773K]  spiece.model\n","├── [2.3K]  tokenizer_config.json\n","└── [2.3M]  tokenizer.json\n","\n","0 directories, 4 files\n"]}]},{"cell_type":"markdown","source":["## Multiple sequences"],"metadata":{"id":"G4w2rQkpuDCx"}},{"cell_type":"markdown","source":["- Batching allows the model to work when you feed it multiple sentences.\n","- Transformers models expect multiple sentences by default.\n","- Output of model has 3 dimensiona as sequence length, the batch size, and the hidden size"],"metadata":{"id":"MTksNsAvuTD8"}},{"cell_type":"code","source":["import torch\n","from torch.nn.functional import softmax\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n","\n","sequence = \"I am a programmer.\"\n","\n","tokens = tokenizer.tokenize(sequence)\n","ids = tokenizer.convert_tokens_to_ids(tokens)\n","\n","input_ids = torch.tensor([ids])\n","print(\"Input IDs:\", input_ids)\n","\n","output = model(input_ids)\n","\n","print(\"Output:\", print)\n","print(\"Output Logits:\", output.logits)\n","print(\"Softmax probabilities:\", softmax(output.logits, dim=1))\n","print(\"Output dimensions:\", output.logits.size())\n","print(\"Batch size:\", output.logits.size(0))\n","print(\"Hidden size:\", output.logits.size(-1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rVvX3p0lugYQ","executionInfo":{"status":"ok","timestamp":1688141711413,"user_tz":-540,"elapsed":1509,"user":{"displayName":"Jing Wora","userId":"14098338404840441752"}},"outputId":"d5af7ee9-d095-4995-95d5-eb01c08d87b7"},"execution_count":82,"outputs":[{"output_type":"stream","name":"stdout","text":["Input IDs: tensor([[ 1045,  2572,  1037, 20273,  1012]])\n","Output: <built-in function print>\n","Output Logits: tensor([[ 2.1330, -1.7802]], grad_fn=<AddmmBackward0>)\n","Softmax probabilities: tensor([[0.9804, 0.0196]], grad_fn=<SoftmaxBackward0>)\n","Output dimensions: torch.Size([1, 2])\n","Batch size: 1\n","Hidden size: 2\n"]}]},{"cell_type":"markdown","source":["## Padding\n","\n","- To make our tensors have a rectangular shape."],"metadata":{"id":"zpwDTzqLyOJD"}},{"cell_type":"code","source":["model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n","\n","sequence1_ids = [[200, 200, 200]]\n","sequence2_ids = [[200, 200]]\n","batched_ids = [\n","    [200, 200, 200],\n","    [200, 200, tokenizer.pad_token_id],\n","]\n","\n","print(model(torch.tensor(sequence1_ids)).logits)\n","print(model(torch.tensor(sequence2_ids)).logits)\n","print(model(torch.tensor(batched_ids)).logits)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZnbPu6IdytnS","executionInfo":{"status":"ok","timestamp":1688136771275,"user_tz":-540,"elapsed":1355,"user":{"displayName":"Jing Wora","userId":"14098338404840441752"}},"outputId":"9822d0fe-9929-481a-bd64-2ccc1d3b20bf"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1.5694, -1.3895]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.5803, -0.4125]], grad_fn=<AddmmBackward0>)\n","tensor([[ 1.5694, -1.3895],\n","        [ 1.3374, -1.2163]], grad_fn=<AddmmBackward0>)\n"]}]},{"cell_type":"code","source":["# Get padding ID\n","\n","tokenizer.pad_token_id"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bAfFfWzax8cp","executionInfo":{"status":"ok","timestamp":1688136777147,"user_tz":-540,"elapsed":386,"user":{"displayName":"Jing Wora","userId":"14098338404840441752"}},"outputId":"ed9160d6-ea41-48b2-d8e3-0b518e5ecae7"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["sequences = [\"I am a programmer in Japan.\", \"So do I!\"]\n","\n","model_inputs = tokenizer(sequences)# Will pad the sequences up to the maximum sequence length\n","print(\"\\n padding=default\")\n","print(len(model_inputs[\"input_ids\"][0])) # Length\n","print(len(model_inputs[\"input_ids\"][1])) # Length\n","print(tokenizer.decode(model_inputs[\"input_ids\"][0])) # Decode\n","print(tokenizer.decode(model_inputs[\"input_ids\"][1])) # Decode\n","\n","model_inputs = tokenizer(sequences, padding=\"longest\")\n","print(\"\\n padding=longest\")\n","print(len(model_inputs[\"input_ids\"][0])) # Length\n","print(len(model_inputs[\"input_ids\"][1])) # Length\n","print(tokenizer.decode(model_inputs[\"input_ids\"][0])) # Decode\n","print(tokenizer.decode(model_inputs[\"input_ids\"][1])) # Decode\n","\n","# Will pad the sequences up to the model max length\n","# (512 for BERT or DistilBERT)\n","model_inputs = tokenizer(sequences, padding=\"max_length\")\n","print(\"\\n padding=max_length\")\n","print(len(model_inputs[\"input_ids\"][0])) # Length\n","print(len(model_inputs[\"input_ids\"][1])) # Length\n","print(tokenizer.decode(model_inputs[\"input_ids\"][0])) # Decode\n","print(tokenizer.decode(model_inputs[\"input_ids\"][1])) # Decode\n","\n","# Will pad the sequences up to the specified max length\n","model_inputs = tokenizer(sequences, padding=\"max_length\", max_length=6)\n","print(\"\\n padding=max_length, max_length=6\")\n","print(len(model_inputs[\"input_ids\"][0])) # Length\n","print(len(model_inputs[\"input_ids\"][1])) # Length\n","print(tokenizer.decode(model_inputs[\"input_ids\"][0])) # Decode\n","print(tokenizer.decode(model_inputs[\"input_ids\"][1])) # Decode"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UBoiCSu7z8NA","executionInfo":{"status":"ok","timestamp":1688139602803,"user_tz":-540,"elapsed":4,"user":{"displayName":"Jing Wora","userId":"14098338404840441752"}},"outputId":"53f8dcab-1754-4dbf-84c3-b38b6c439047"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," padding=default\n","9\n","6\n","[CLS] i am a programmer in japan. [SEP]\n","[CLS] so do i! [SEP]\n","\n"," padding=longest\n","9\n","9\n","[CLS] i am a programmer in japan. [SEP]\n","[CLS] so do i! [SEP] [PAD] [PAD] [PAD]\n","\n"," padding=max_length\n","512\n","512\n","[CLS] i am a programmer in japan. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","[CLS] so do i! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","\n"," padding=max_length, max_length=6\n","9\n","6\n","[CLS] i am a programmer in japan. [SEP]\n","[CLS] so do i! [SEP]\n"]}]},{"cell_type":"markdown","source":["### Truncate sequences"],"metadata":{"id":"Wof9kJY33FKC"}},{"cell_type":"code","source":["# Will truncate the sequences that are longer than the specified max length\n","model_inputs = tokenizer(sequences, max_length=6, truncation=True)\n","\n","print(\"\\n  max_length=8, truncation=True\")\n","print(tokenizer.decode(model_inputs[\"input_ids\"][0])) # Decode\n","print(tokenizer.decode(model_inputs[\"input_ids\"][1])) # Decode"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zkmMMWEO3Le9","executionInfo":{"status":"ok","timestamp":1688138005282,"user_tz":-540,"elapsed":2,"user":{"displayName":"Jing Wora","userId":"14098338404840441752"}},"outputId":"ade9949b-44d4-4eb5-eed7-b407c3e3e807"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","  max_length=8, truncation=True\n","[CLS] i am a programmer [SEP]\n","[CLS] so do i! [SEP]\n"]}]},{"cell_type":"markdown","source":["### Conversion framework"],"metadata":{"id":"x7GHJfeq4Fxm"}},{"cell_type":"code","source":["# Returns PyTorch tensors\n","model_inputs = tokenizer(sequences, padding=True, return_tensors=\"pt\")\n","print(type(model_inputs[\"input_ids\"]))\n","\n","# Returns TensorFlow tensors\n","model_inputs = tokenizer(sequences, padding=True, return_tensors=\"tf\")\n","print(type(model_inputs[\"input_ids\"]))\n","\n","# Returns NumPy arrays\n","model_inputs = tokenizer(sequences, padding=True, return_tensors=\"np\")\n","print(type(model_inputs[\"input_ids\"]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uelIbEaj4FGA","executionInfo":{"status":"ok","timestamp":1688138370934,"user_tz":-540,"elapsed":4,"user":{"displayName":"Jing Wora","userId":"14098338404840441752"}},"outputId":"e71e28cf-b0a8-4d4a-fe4e-9c89c676eff3"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'torch.Tensor'>\n","<class 'tensorflow.python.framework.ops.EagerTensor'>\n","<class 'numpy.ndarray'>\n"]}]},{"cell_type":"markdown","source":["## Special tokens\n","- Special tokens refer to specific tokens that have special meanings in natural language processing tasks. They are often used to handle various aspects of language modeling, such as indicating the start and end of a sentence, marking out-of-vocabulary words, separating sentences, or representing padding and masking."],"metadata":{"id":"Ju-RdlhH5EKD"}},{"cell_type":"code","source":["sequence = \"I am a programmer.\"\n","\n","model_inputs = tokenizer(sequence)\n","print(model_inputs[\"input_ids\"])\n","\n","tokens = tokenizer.tokenize(sequence)\n","ids = tokenizer.convert_tokens_to_ids(tokens)\n","print(ids)\n","\n","# Encode\n","print(tokenizer.decode(model_inputs[\"input_ids\"]))\n","print(tokenizer.decode(ids))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SskMGMV_5DU0","executionInfo":{"status":"ok","timestamp":1688138720387,"user_tz":-540,"elapsed":358,"user":{"displayName":"Jing Wora","userId":"14098338404840441752"}},"outputId":"1bc132e8-80aa-4693-f39e-c584de5ca70d"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["[101, 1045, 2572, 1037, 20273, 1012, 102]\n","[1045, 2572, 1037, 20273, 1012]\n","[CLS] i am a programmer. [SEP]\n","i am a programmer.\n"]}]},{"cell_type":"markdown","source":["## Attention masks\n","\n","- Attention masks are tensors with the exact same shape as the input IDs tensor, filled with 0s and 1s: 1s indicate the corresponding tokens should be attended to, and 0s indicate the corresponding tokens should not be attended to (ignore)."],"metadata":{"id":"1kvcOt4VyUx-"}},{"cell_type":"code","source":["batched_ids = [\n","    [200, 200, 200],\n","    [200, 200, tokenizer.pad_token_id],\n","]\n","\n","attention_mask = [\n","    [1, 1, 1],\n","    [1, 1, 0],\n","]\n","\n","outputs = model(torch.tensor(batched_ids), attention_mask=torch.tensor(attention_mask))\n","print(outputs.logits)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PHeM3kwyy2kr","executionInfo":{"status":"ok","timestamp":1688139718439,"user_tz":-540,"elapsed":342,"user":{"displayName":"Jing Wora","userId":"14098338404840441752"}},"outputId":"b8c4748a-b083-4431-8a2e-50a88eb0dd44"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1.5694, -1.3895],\n","        [ 0.5803, -0.4125]], grad_fn=<AddmmBackward0>)\n","2\n"]}]},{"cell_type":"markdown","source":["Notice how the last value of the second sequence is a padding ID, which is a 0 value in the attention mask."],"metadata":{"id":"E1h70Qmuy8Ee"}},{"cell_type":"markdown","source":["## Longer sequences\n","- With Transformer models, there is a limit to the lengths of the sequences we can pass the models. Most models handle sequences of up to 512 or 1024 tokens.\n","-  There are two solutions to this problem:\n","  - Use a model with a longer supported sequence length.\n","  - Truncate your sequences."],"metadata":{"id":"-SUg2R2EzCLk"}},{"cell_type":"markdown","source":["## Reference:\n","\n","- Hugging Face NLP Course\n","  - https://huggingface.co/learn/nlp-course/chapter1/1\n","\n","- datacamp: An Introduction to Using Transformers and Hugging Face\n","  - https://www.datacamp.com/tutorial/an-introduction-to-using-transformers-and-hugging-face"],"metadata":{"id":"P4ysUFh1L8dl"}}]}